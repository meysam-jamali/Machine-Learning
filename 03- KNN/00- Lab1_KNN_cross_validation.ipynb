{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Part 1 - K-Nearest Neighbours\n",
    "\n",
    "This lab is about the implementation and analysis of the KNN algorithm for classification and regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import pickle\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation for binary classification\n",
    "\n",
    "We start generating a training set for binary classification problems. Consider the following function, that generates random 2D points on the plane and assigns them a binary label according to their position wrt a linear separator.\n",
    "\n",
    "The use of the function is the following:\n",
    "\n",
    "**X, Y = linearBinaryClass(n, low_D, high_D, m, q)**\n",
    "\n",
    "where\n",
    "- **n** is the number of samples to be generated\n",
    "- **low_D** and **high_D** are, respectively, the lower and upper bounds for the domain of the samples\n",
    "- **m, q** are the linear function parameters\n",
    "- **X**, **Y**: 2-dimensional samples (X) associated with 1-dimensional binary labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearBinaryClass(n, low_D, high_D, m, q):\n",
    "    X = np.zeros((n, 2))\n",
    "    Y = np.zeros(n)\n",
    "    for i in range(2):\n",
    "        X[:,i] = np.random.uniform(low_D, high_D, size=n)\n",
    "        \n",
    "    Y[X[:,1] - (X[:,0] * m + q) > 0] = 1 \n",
    "    Y[Y==0] = -1\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the distance between input points\n",
    "\n",
    "In order to build the KNN estimator we need to resort to a distance function.\n",
    "\n",
    "Consider a function that computes the euclidean distance between two points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidDistance(P1,P2):\n",
    "    return np.linalg.norm(P1-P2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then a function that computes all the distance between two set of points stored in two matrices. The usage is the following:\n",
    "\n",
    "**D = allDistances(X1,X2)**\n",
    "where\n",
    "- **X1** is a matrix of size [n1xD], where each row is a D-dimensional point\n",
    "- **X2** is a matrix of size [n2xD], where each row is a D-dimensional point\n",
    "- **D** is a matrix of size [n1xn2], where each element `D[i,j]` is the distance between points (`X1[i, :]`, `X2[j, :]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDistances(X1, X2):\n",
    "    D = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "    for idx1 in range(len(X1)):\n",
    "        for idx2 in range(len(X2)):\n",
    "            D[idx1,idx2] = euclidDistance(X1[idx1,:],X2[idx2,:])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise to the samples\n",
    "\n",
    "To make the task harder, we may want to perturb the labels with some noise.\n",
    "\n",
    "In our case, we have binary labels and a common way of adding noise is to flip the value of a small percentage of the labels. For example, if a label was $+1$ it will become $-1$.\n",
    "\n",
    "The `flipLabels` function takes two arguments:\n",
    " - `Y`, the numpy array of original labels\n",
    " - `P`, an integer between 1 and 100 specifying the percentage of labels which will be flipped\n",
    "and returns an array of the same shape as `Y`, which contains the noisy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipLabels(Y, P):\n",
    "    if P < 1 or P > 100:\n",
    "        print(\"p should be a percentage value between 0 and 100.\")\n",
    "        return -1\n",
    "\n",
    "    if any(np.abs(Y) != 1):\n",
    "        print(\"The values of Ytr should be +1 or -1.\")\n",
    "        return -1\n",
    "\n",
    "    Y_noisy = np.copy(np.squeeze(Y))\n",
    "    if Y_noisy.ndim > 1:\n",
    "        print(\"Please supply a label array with only one dimension\")\n",
    "        return -1\n",
    "\n",
    "    n = Y_noisy.size\n",
    "    n_flips = int(np.floor(n * P / 100))\n",
    "    idx_to_flip = np.random.choice(n, size=n_flips, replace=False)\n",
    "    Y_noisy[idx_to_flip] = -Y_noisy[idx_to_flip]\n",
    "\n",
    "    return Y_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The KNN classifier\n",
    "\n",
    "We are now ready to use the KNN algorithm to estimate the classification function. The use is as follow:\n",
    "\n",
    "**_Ypred = kNNClassify(Xtr, Ytr, k, Xte)_**\n",
    "\n",
    "where\n",
    "- **Xtr** is a matrix of size [ntr, D], where each row is a D-dimensional point (INPUT IN THE **TRAINING SET**)\n",
    "- **Ytr** is an array of size [ntr], where each element is a binary label (OUTPUT IN THE **TRAINING SET**)\n",
    "- **k** is the number of neighbours to be considered\n",
    "- **Xte** is a matrix of size [nte, D], where each row is a D-dimensional point (INPUT IN THE **TEST SET**)\n",
    "- **Ypred** is an array of size [nte], where each element is a binary label (ESTIMATED OUTPUT FOR THE **TEST SET**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNNClassify(Xtr, Ytr, k, Xte):\n",
    "\n",
    "    n_train = Xtr.shape[0]\n",
    "    n_test = Xte.shape[0]\n",
    "\n",
    "    if any(np.abs(Ytr) != 1):\n",
    "        print(\"The values of Ytr should be +1 or -1.\")\n",
    "        return -1\n",
    "\n",
    "    if k > n_train:\n",
    "        print(\"k is greater than the number of points, setting k=n_train\")\n",
    "        k = n_train\n",
    "\n",
    "    Ypred = np.zeros(n_test)\n",
    "\n",
    "    dist = allDistances(Xte, Xtr)\n",
    "\n",
    "    for idx in range(n_test):\n",
    "        neigh_indexes = np.argsort(dist[idx, :])[:k]\n",
    "        avg_neigh = np.mean(Ytr[neigh_indexes])\n",
    "        Ypred[idx] = np.sign(avg_neigh)\n",
    "\n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the separating function\n",
    "\n",
    "The visualization of the separating function on the training set, i.e. the function estimated by classification algorithm for discriminating between classes, is of benefit for appreciating the behavior of the binary classifier. To visualize the separating function use the following:\n",
    "\n",
    "**_separatingFkNN(Xtr, Ytr, k)_**\n",
    "\n",
    "where\n",
    "- **Xtr** is a matrix of size [ntr, D], where each row is a D-dimensional point (INPUT IN THE **TRAINING SET**)\n",
    "- **Ytr** is an array of size [ntr], where each element is a binary label (OUTPUT IN THE **TRAINING SET**)\n",
    "- **k** is the number of neighbours to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatingFkNN(Xtr, Ytr, k):\n",
    "    Ypred = kNNClassify(Xtr=Xtr, Ytr=Ytr, k=k, Xte=Xtr)\n",
    "\n",
    "    x = Xtr[:, 0]\n",
    "    y = Xtr[:, 1]\n",
    "    xi = np.linspace(x.min(), x.max(), 200)\n",
    "    yi = np.linspace(y.min(), y.max(), 200)\n",
    "    zi = griddata((x, y), Ypred, (xi[None, :], yi[:, None]), method='linear')\n",
    "\n",
    "    plt.subplots()\n",
    "    CS = plt.contour(xi, yi, zi, 15, linewidths=2, colors='k', levels=[0])\n",
    "    # plot data points.\n",
    "    plt.scatter(x, y, c=Ytr, marker='o', s=50, zorder=10, alpha=0.8)\n",
    "    plt.xlim(x.min(), x.max())\n",
    "    plt.ylim(x.min(), x.max())\n",
    "    msg = 'Separating function, k='+str(k);\n",
    "    plt.title(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the goodness of a classifier\n",
    "\n",
    "To evaluate how good is the classification function estimated by the KNN, we compare the predicted binary labels and expected (true) ones, with the following function:\n",
    "\n",
    "**_acc = calcAccuracy(Ypred, Ytrue)_**\n",
    "\n",
    "where\n",
    "- **Ypred** is an array of size [ntr], where each element is a binary label predicted by the classifier\n",
    "- **Ytrue** is an array of size [ntr], where each element is the true binary label\n",
    "- **acc** is the fraction of correctly classified elements wrt the total number\n",
    "\n",
    "Similarly we have the `calcError` function which returns the fraction of incorrectly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(Ypred, Ytrue):\n",
    "    return (np.count_nonzero(Ypred == Ytrue)) / len(Ytrue)\n",
    "\n",
    "def calcError(Ypred, Ytrue):\n",
    "    return (np.count_nonzero(Ypred != Ytrue)) / len(Ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and test sets, build and evaluate the KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "D = 2\n",
    "\n",
    "m = 0.9\n",
    "q = 0.0\n",
    "\n",
    "low_D = -10\n",
    "high_D = 10\n",
    "\n",
    "k = 1\n",
    "\n",
    "# Generate a training set WITHOUT NOISE\n",
    "Xtr, Ytr = linearBinaryClass(n, low_D, high_D, m, q)\n",
    "\n",
    "# Visualize the separating curve for the NN classifier \n",
    "separatingFkNN(Xtr, Ytr, k)\n",
    "\n",
    "# Generate a test set WITHOUT NOISE\n",
    "Xte, Yte = linearBinaryClass(n, low_D, high_D, m, q)\n",
    "\n",
    "# Evaluate the NN classifier on the TEST SET -> Prediction\n",
    "Ypred = kNNClassify(Xtr, Ytr, k, Xte)\n",
    "\n",
    "# Compute the accuracy on the TEST SET\n",
    "acc = calcAccuracy(Ypred, Yte)\n",
    "\n",
    "print(\"With K=%d the accuracy on the test set is \" % (k), acc)\n",
    "\n",
    "# How the classifier perform on the TRAINING SET instead?\n",
    "Ypredtr = kNNClassify(Xtr, Ytr, k, Xtr)\n",
    "acctr = calcAccuracy(Ypredtr, Ytr)\n",
    "print(\"With K=%d the accuracy on the training set is \" % (k), acctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1\n",
    "\n",
    "Keeping the parameters of the function and the number of points as in the previous example:\n",
    "\n",
    "- 1.Generate a training set WITH NOISE (for instance with 10% of flipped labels)\n",
    "- 2.Visualize the separating curve for the **NN** classifier \n",
    "- 3.Generate a test set with the same amount of noise as the training set.\n",
    "- 4.Evaluate the NN classifier first on the TRAINING and then on the TEST SET\n",
    "- 5.Compute the obtained accuracy first on the TRAINING and then on the TEST SET\n",
    "\n",
    "- Repeat the steps from 1 to 5 with the **KNN** algorithm, setting for instance K=5\n",
    "\n",
    "OBSERVE WHAT CHANGES...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "Analyse the performance of the **KNN** with plots, considering in particular the following:\n",
    "\n",
    "- **SCENARIO 1**: Fix the number n of points to 200, fix the amount of noise to 10%, and plot the performance of the KNN classifier on TRAINING an TEST SETS as you increase the value of K\n",
    "\n",
    "- **SCENARIO 2**: Fix the number n of points to 200, fix the value of K to a reasonable number of neighbours, and plot the performance of the KNN classifier on TRAINING an TEST SETS as you increase the amount of noise\n",
    "\n",
    "- **SCENARIO 3**: Fix noise and K to two reasonable values, fix the number of TEST samples to 300, and plot the performance of the KNN classifier on TRAINING an TEST SETS as you increase the number of TRAINING samples (e.g. from 30 to 300 with steps 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code for SCENARIO 1 goes here...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code for SCENARIO 2 goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code for SCENARIO 3 goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Cross Validation for KNN\n",
    "\n",
    "So far you experienced how the use of different possible values of K may influence the results, also depending on the type of data, their cardinality, and the amount of noise.\n",
    "\n",
    "**We now apply Cross Validation for the choice of an appropriate value for the parameter K.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the test error for different values of K\n",
    "\n",
    "Having access to both the training and the test, we may start by having a look at the trend of the test error as the value of K increases. To this purpose we use the function\n",
    "\n",
    "**_train_err, test_err = trainTestAnalysis(k_list, Xtr, Ytr, Xte, Yte)_**\n",
    "\n",
    "where\n",
    "- **k_list**: array of possible values for K to be considered\n",
    "- **Xtr** and **Ytr**: respectively, input and output of the training set\n",
    "- **Xts** and **Yts**: respectively, input and output of the test set\n",
    "- **train_err**, **test_err**: array of errors on training and test for different values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestAnalysis(k_list, Xtr, Ytr, Xte, Yte):\n",
    "    train_err = np.zeros(len(k_list))\n",
    "    test_err = np.zeros(len(k_list))\n",
    "\n",
    "    for kdx, k in enumerate(k_list):\n",
    "        Ypredte = kNNClassify(Xtr, Ytr, k, Xte)\n",
    "        test_err[kdx] = calcError(Ypredte, Yte)\n",
    "        \n",
    "        Ypredtr = kNNClassify(Xtr, Ytr, k, Xtr)\n",
    "        train_err[kdx] = calcError(Ypredtr, Ytr)\n",
    "\n",
    "    return train_err, test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def KFoldCVkNN(Xtr, Ytr, KF, k_list):\n",
    "    if KF <= 0:\n",
    "        print(\"Please supply a positive number of repetitions\")\n",
    "        return -1\n",
    "\n",
    "    # Ensures that k_list is a numpy array\n",
    "    k_list = np.array(k_list)\n",
    "    num_k = k_list.size\n",
    "\n",
    "    n_tot = Xtr.shape[0]\n",
    "    n_val = int(n_tot // KF)\n",
    "\n",
    "    # We want to compute 1 error for each `k` and each fold\n",
    "    tr_errors = np.zeros((num_k, KF))\n",
    "    val_errors = np.zeros((num_k, KF))\n",
    "\n",
    "    for kdx, k in enumerate(k_list):\n",
    "        # `split_idx`: a list of arrays, each containing the validation indices for 1 fold\n",
    "        rand_idx = np.random.choice(n_tot, size=n_tot, replace=False)\n",
    "        split_idx = np.array_split(rand_idx, KF)\n",
    "        for fold in range(KF):\n",
    "            # Set the indices in boolean mask for all validation samples to `True`\n",
    "            val_mask = np.zeros(n_tot, dtype=bool)\n",
    "            val_mask[split_idx[fold]] = True\n",
    "\n",
    "            X = Xtr[~val_mask]\n",
    "            Y = Ytr[~val_mask]\n",
    "            X_val = Xtr[val_mask]\n",
    "            Y_val = Ytr[val_mask]\n",
    "            \n",
    "            # Compute the training error of the kNN classifier for the given value of k\n",
    "            tr_errors[kdx, fold] = calcError(kNNClassify(X, Y, k, X), Y)\n",
    "\n",
    "            # Compute the validation error of the kNN classifier for the given value of k\n",
    "            val_errors[kdx, fold] = calcError(kNNClassify(X, Y, k, X_val), Y_val)\n",
    "\n",
    "    # Calculate error statistics along the repetitions\n",
    "    tr_mean = np.mean(tr_errors, axis=1)\n",
    "    tr_var = np.var(tr_errors, axis=1)\n",
    "    val_mean = np.mean(val_errors, axis=1)\n",
    "    val_var = np.var(val_errors, axis=1)\n",
    "\n",
    "    best_k_idx = np.argmin(val_mean)\n",
    "    best_k = k_list[best_k_idx]\n",
    "\n",
    "    return best_k, val_mean, val_var, tr_mean, tr_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying model selection with different strategies\n",
    "\n",
    "It is now time to try and compare different strategies for selecting the best value for the parameter K. To this purpose we provide you some example datasets for binary classification problems (see Material.zip) you can play with. \n",
    "\n",
    "The datasets have the following properties:\n",
    "- (Training1, Test1): n=70, no noise, suggested K values are in the range 1 ... 13\n",
    "- (Training2, Test2): n=40, no noise, suggested K values are in the range 1 ... 23\n",
    "- (Training3, Test3): n=200, 20% flipped labels, suggested K values are in the range 1 ... 31\n",
    "- (Training4, Test4): n=200, 5% flipped labels, suggested K values are in the range 1 ... 19\n",
    "\n",
    "To load a dataset (e.g. Training1/Test1) use the following:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Material/Training1.dat\",\"rb\") as f:\n",
    "    [Xtr, Ytr] = pickle.load(f)\n",
    "with open(\"Material/Test1.dat\",\"rb\") as f:\n",
    "    [Xte, Yte] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To plot the results of cross-validation you may use the following function. It expects as inputs the list of values of k which were tested, and training and validation errors with their respective variance.\n",
    "\n",
    "As an example usage, you could run:\n",
    "```python\n",
    "k_list = [1, 2, 3]\n",
    "best_k, val_err, val_var, tr_err, tr_var = KFoldCVkNN(Xtr, Ytr, 5, k_list)\n",
    "plot_knn_errors(k_list, val_err, val_var, tr_err, tr_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knn_errors(k_list, val_mean, val_var, tr_mean, tr_var):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.errorbar(k_list, val_mean, val_var, label=\"Validation eror\")\n",
    "    ax.errorbar(k_list, tr_mean, tr_var, label=\"Training error\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Only show integer labels on x-axis\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_ylabel(\"Error (misclassified fraction)\")\n",
    "    ax.set_xlabel(\"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = np.arange(1, 15, 2)\n",
    "best_k, val_err, val_var, tr_err, tr_var = KFoldCVkNN(Xtr, Ytr, 5, k_list)\n",
    "plot_knn_errors(k_list, val_err, val_var, tr_err, tr_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_err, test_err] = trainTestAnalysis(np.arange(1, 15, 2), Xtr, Ytr, Xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot training, test and validation errors in the same plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(k_list, train_err, label=\"Training error\")\n",
    "ax.errorbar(k_list, val_err, val_var, label=\"Validation eror\")\n",
    "ax.plot(k_list, test_err, label=\"Test eror\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Only show integer labels on x-axis\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel(\"Error (misclassified fraction)\")\n",
    "ax.set_xlabel(\"K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To go deeper:\n",
    "1. Run k-fold CV for different numbers of folds.\n",
    "   - Compare the optimal `k` as given by cross-validation with the best `k` on the test dataset (you can get this with the `trainTestAnalysis` function). _Use the noise-less datasets for clearer results._\n",
    "2. Compare results on the noisy, and noise-less datasets:\n",
    "    - How does the optimal `k` change as the noise is increased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert your code for the assignments here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
