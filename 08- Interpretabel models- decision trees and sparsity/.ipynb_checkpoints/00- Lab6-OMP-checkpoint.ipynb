{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. 6 - Variable selection\n",
    "\n",
    "In this lab we will move to considering the problems of variable selection in classification (thus supervised) scenarios.\n",
    "\n",
    "As usual, we start importing libraries and functions already used in one of the previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "\n",
    "rnd_state = np.random.RandomState(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "To generate a synthetic dataset suitable for use with variable selection, we first generate a subset of \"relevant\" features, and then concatenate with a second set of \"dummy\", irrelevant featuers. To this purpose,  we proceed as follows:\n",
    "- Generate a dataset with the `mixGauss` function: use two Gaussians which are *close* with each other (see example below). Start by considering 2-Dimensional points\n",
    "- Plot the points: you should observe two point-clouds which mix with each other (since they were generated with the same parameters).\n",
    "- Enrich the input samples with \"dummy\" features randomly sampled and concatenate to the relevant features (notice that at this point data visualization is no more possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixGauss(means, sigmas, n):\n",
    "\n",
    "    means = np.array(means)\n",
    "    sigmas = np.array(sigmas)\n",
    "\n",
    "    d = means.shape[1]\n",
    "    num_classes = sigmas.size\n",
    "    data = np.full((n * num_classes, d), np.inf)\n",
    "    labels = np.zeros(n * num_classes)\n",
    "\n",
    "    for idx, sigma in enumerate(sigmas):\n",
    "        data[idx * n:(idx + 1) * n] = rnd_state.multivariate_normal(\n",
    "            mean=means[idx], cov=np.eye(d) * sigmas[idx] ** 2, size=n)\n",
    "        labels[idx * n:(idx + 1) * n] = idx \n",
    "        \n",
    "    if(num_classes == 2):\n",
    "        labels[labels==0] = -1\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000 # number of features for each gaussian\n",
    "d=30 # total number of features\n",
    "d_rev = 2 # number of relevant features\n",
    "\n",
    "Xtr, Ytr = mixGauss(means = [[0,0],[2,2]], sigmas = [0.9, 0.75], n=n)\n",
    "Xte, Yte = mixGauss(means = [[0,0],[2,2]], sigmas = [0.9, 0.75], n=n)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Training Set\", fontsize=22)\n",
    "ax.scatter(Xtr[Ytr==-1,0], Xtr[Ytr==-1,1], s=30, alpha=0.80)\n",
    "ax.scatter(Xtr[Ytr==1,0], Xtr[Ytr==1,1], s=30, alpha=0.80)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Test Set\", fontsize=22)\n",
    "ax.scatter(Xte[Yte==-1,0], Xte[Yte==-1,1], s=30, alpha=0.80)\n",
    "ax.scatter(Xte[Yte==1,0], Xte[Yte==1,1], s=30, alpha=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy features generation\n",
    "sigma_noise = 0.13\n",
    "Xtr_noise = sigma_noise * rnd_state.randn(2*n, d-d_rev)\n",
    "Xtr = np.concatenate((Xtr,Xtr_noise), axis=1)\n",
    "Xte_noise = sigma_noise * rnd_state.randn(2*n, d-d_rev)\n",
    "Xte = np.concatenate((Xte,Xte_noise), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OMatchingPursuit\n",
    "\n",
    "It computes a sparse representation of the signal using Orthogonal Matching Pursuit algorithm. Use it as follows:\n",
    "    \n",
    "`w, r, I = OMatchingPursuit( X, Y, T)`\n",
    "\n",
    "where\n",
    "    - X: input data\n",
    "    - Y: output labels\n",
    "    - T: number of iterations\n",
    "    - w: estimated coefficients\n",
    "    - r: residuals\n",
    "    - I: indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMatchingPursuit(X, Y, T):\n",
    "\n",
    "    N, D = np.shape(X)\n",
    "\n",
    "    # 1. Initialization of residual, coefficient vector and index set I\n",
    "    r = Y\n",
    "    w = np.zeros(D)\n",
    "    I = []\n",
    "\n",
    "    for i in range(T):\n",
    "        I_tmp = range(D)\n",
    "\n",
    "        # 2. Select the column of X which coefficients most \"explains\" the residual\n",
    "        a_max = -1\n",
    "\n",
    "        for j in I_tmp:\n",
    "            a_tmp = ...\n",
    "\n",
    "            if a_tmp > a_max:\n",
    "                a_max = a_tmp\n",
    "                j_max = j\n",
    "\n",
    "        # 3. Add the index to the set of indexes\n",
    "        if j_max not in I:\n",
    "            I.append(j_max)\n",
    "\n",
    "        # Compute the M matrix\n",
    "        M_I = np.zeros((D, D))\n",
    "\n",
    "        for j in I:\n",
    "            M_I[j, j] = 1\n",
    "\n",
    "        A = M_I.dot(X.T).dot(X).dot(M_I)\n",
    "        B = M_I.dot(X.T).dot(Y)\n",
    "\n",
    "        # 4. Update estimated coefficients\n",
    "        w = ...\n",
    "\n",
    "        # 5. Update the residual\n",
    "        r = ...\n",
    "\n",
    "    return w, r, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual function to compute the error in predicted labels (for a binary classification problem)\n",
    "def calcError(Ypred, Y):\n",
    "    V = np.multiply(np.sign(Ypred), np.sign(Y))\n",
    "    return np.count_nonzero(V < 0) / len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation for selecting the best value for the hyperparameters in the use of \n",
    "# Orthogonal Matching Pursuit (we refer to the number of iterations)\n",
    "\n",
    "def KFoldCVOMP(Xtr, Ytr, KF, niter_list):\n",
    "    if KF <= 0:\n",
    "        print(\"Please supply a positive number of repetitions\")\n",
    "        return -1\n",
    "\n",
    "    # Ensures that k_list is a numpy array\n",
    "    niter_list = np.array(niter_list)\n",
    "    num_niter = niter_list.size\n",
    "\n",
    "    n_tot = Xtr.shape[0]\n",
    "    n_val = int(np.floor(n_tot/KF))\n",
    "\n",
    "    Tm = np.zeros(num_niter)\n",
    "    Ts = np.zeros(num_niter)\n",
    "    Vm = np.zeros(num_niter)\n",
    "    Vs = np.zeros(num_niter)\n",
    "\n",
    "    # Random permutation of training data\n",
    "    rand_idx = rnd_state.choice(n_tot, size=n_tot, replace=False)\n",
    "    \n",
    "    \n",
    "    for kdx, niter in enumerate(niter_list):\n",
    "        first = 0\n",
    "        for fold in range(KF):\n",
    "            flags = np.zeros(Xtr.shape[0])\n",
    "            flags[first:first+n_val]=1;\n",
    "            \n",
    "            X = Xtr[rand_idx[flags==0]]\n",
    "            Y = Ytr[rand_idx[flags==0]]\n",
    "            X_val = Xtr[rand_idx[flags==1]]\n",
    "            Y_val = Ytr[rand_idx[flags==1]]\n",
    "\n",
    "            # Compute the training error of OMP for the given number of iterations\n",
    "            w, r, I = OMatchingPursuit(X, Y, niter)\n",
    "            YpredTR = np.sign(X.dot(w))\n",
    "            trError = calcError(YpredTR, Y)\n",
    "            Tm[kdx] = Tm[kdx] + trError\n",
    "            Ts[kdx] = Ts[kdx] + trError ** 2\n",
    "\n",
    "            # Compute the validation error OMP for the given number of iterations\n",
    "            YpredVAL = np.sign(X_val.dot(w))\n",
    "            valError = calcError(YpredVAL, Y_val)\n",
    "            Vm[kdx] = Vm[kdx] + valError\n",
    "            Vs[kdx] = Vs[kdx] + valError ** 2\n",
    "            \n",
    "            first = first+n_val                \n",
    "\n",
    "    Tm = Tm / KF\n",
    "    Ts = Ts / KF - Tm ** 2\n",
    "\n",
    "    Vm = Vm / KF\n",
    "    Vs = Vs / KF - Vm ** 2\n",
    "\n",
    "    best_niter_idx = np.argmin(Vm)\n",
    "    bestniter = niter_list[best_niter_idx]\n",
    "    \n",
    "    print(Vm)\n",
    "    print(niter_list)\n",
    "    print(best_niter_idx)\n",
    "\n",
    "    return bestniter, Vm, Vs, Tm, Ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some analysis\n",
    "\n",
    "We suggest to proceed as follows:\n",
    "\n",
    "- Standardize the data\n",
    "- Run Orthogonal Matching Pursuit on the training set setting a reasonable number of iterations\n",
    "- Compute the prediction on the test set and evaluate the error\n",
    "- Plot the components of the solution w (considering their absolute value): how do they look?\n",
    "- Run the K-Fold Cross Validation to select an appropriate value for the number of iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization\n",
    "m = np.mean(Xtr, axis=0)\n",
    "s = np.std(Xtr, axis=0)\n",
    "Xtrnorm = np.divide((Xtr - m), s)\n",
    "Xtenorm = np.divide((Xte - m), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Orthogonal Matching Pursuit\n",
    "# ... fill here ...\n",
    "\n",
    "# Compute the prediction on the test set\n",
    "# ... fill here ...\n",
    "\n",
    "# Compute the test error and show its value\n",
    "# ... fill here ...\n",
    "\n",
    "# Plot the components of the solution w\n",
    "# ... fill here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run K-Fold Cross Validation\n",
    "KF = 5\n",
    "niter_list = [1, 2, 3, 4, 5, 10, d] \n",
    "bestniter, Vm, Vs, Tm, Ts = ...\n",
    "\n",
    "# Plot training and validation error\n",
    "plt.subplots()\n",
    "plt.plot(niter_list, Tm, label=\"training\")\n",
    "plt.plot(niter_list, Vm, label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"number of iterations\")\n",
    "plt.axvline(bestniter, color=\"red\")\n",
    "print('Best number of iterations: '+str(bestniter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also shuffle columns of the synthetic dataset in order to observe the behavior of OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle columns\n",
    "shuffle_idx = rnd_state.choice(Xtr.shape[1], Xtr.shape[1], replace=False)\n",
    "\n",
    "Xtr = Xtr[:, shuffle_idx]\n",
    "Xte = Xte[:, shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[--] The relevant features are {} and {}\".format((shuffle_idx == 0).argmax(), (shuffle_idx == 1).argmax() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OMP and verify that it is able to find the relevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the number of relevant and dummy features and observe the behavior of OMP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
